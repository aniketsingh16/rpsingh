from src.ingest import load_incident
from src.summarize import summarize_incident
from src.extract import extract_incident_details
from src.rca import generate_rca_and_prevention

FILE_PATH = "data/raw_incidents/incident1.txt"

def main():
    text = load_incident(FILE_PATH)

    print("\n--- INCIDENT SUMMARY ---")
    print(summarize_incident(text))

    print("\n--- STRUCTURED DETAILS ---")
    print(extract_incident_details(text))

    print("\n--- RCA & PREVENTION ---")
    print(generate_rca_and_prevention(text))

if __name__ == "__main__":
    main()
 


.....from src.llm_utils import call_llm

def generate_rca_and_prevention(text: str) -> str:
    prompt = f"""
    Analyze the following incident and explain:
    1. Why it happened
    2. What systemic issue caused it
    3. How similar incidents can be prevented

    Incident:
    {text}
    """

    return call_llm(prompt, model="deepseek-r1")
 

.
import json
from src.llm_utils import call_llm

def extract_incident_details(text: str) -> dict:
    prompt = f"""
    Extract key incident details in JSON format with keys:
    trigger, impact, timeline, actions_taken, root_cause.

    Incident:
    {text}
    """

    response = call_llm(prompt, model="gemma3")

    try:
        return json.loads(response)
    except json.JSONDecodeError:
        return {"raw_output": response}
 
..
.from src.llm_utils import call_llm

def summarize_incident(text: str) -> str:
    prompt = f"""
    Summarize the following DevOps incident in 3-4 concise sentences:

    {text}
    """
    return call_llm(prompt, model="llama3.2")
 

..
from pathlib import Path

def load_incident(file_path: str) -> str:
    path = Path(file_path)

    if not path.exists():
        raise FileNotFoundError(f"{file_path} not found")

    return path.read_text(encoding="utf-8").strip()
 

..
import subprocess

def call_llm(prompt: str, model: str) -> str:
    result = subprocess.run(
        ["ollama", "run", model],
        input=prompt,
        text=True,
        capture_output=True
    )

    if result.returncode != 0:
        raise RuntimeError(result.stderr)

    return result.stdout.strip()

You said:
DevOps teams handle numerous incident reports and post-mortems, which are often lengthy and inconsistent in format. Extracting actionable insights and root causes from these documents is time-intensive, delaying resolution and learning. A generative Al agent that summarizes incidents, highlights critical actions taken, and recommends preventive measures can streamline incident management. This improves team responsiveness and knowledge retention, reducing incident.

Hey, I'm in an AI hackathon internal hackathon by TCS. I need your help in the above problem statement.  you have to provide an innovative answer.


type nul > src\ingest.py
type nul > src\llm_utils.py
type nul > src\summarize.py
type nul > src\extract.py
type nul > src\rca.py

type nul > demo.py
type nul > README.md

type nul > data\raw_incidents\incident1.txt

Incident ID: INC-1024

At 14:02 IST, a configuration change was deployed to the Kubernetes autoscaler.
Within minutes, the Payments API experienced increased latency.
Alerts triggered at 14:05, and the on-call engineer investigated.
The root cause was an invalid HPA configuration without proper limits.
Service was restored by rolling back the configuration at 14:30.

Impact: Payment transactions were delayed for 28 minutes.

